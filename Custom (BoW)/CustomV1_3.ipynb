{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomV1-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l91f0FH8cQB_",
        "colab_type": "text"
      },
      "source": [
        "Definitions of Classes and Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lIHEZFZ0usJ",
        "colab_type": "text"
      },
      "source": [
        "Needs Troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csECAEcybQx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Progress Counter\n",
        "import sys\n",
        "\n",
        "class progressCounter():\n",
        "\n",
        "  def __init__(self, num_iterations, name=''):\n",
        "    self.progress = 0\n",
        "    self.N = num_iterations\n",
        "    self.name = name\n",
        "\n",
        "  def check_pt(self, i):\n",
        "    curr_progress = int(i/(self.N-1) * 100)\n",
        "    if curr_progress - self.progress > 0:\n",
        "      self.progress = curr_progress\n",
        "      sys.stdout.write(\"\\r{1} Progress: {0}%\".format(self.progress, self.name))\n",
        "      sys.stdout.flush()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcKATs2PbZII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cosine Similarity Function\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "# takes in 2 numpy arrays\n",
        "def compute_cosine_similarity(v1, v2):\n",
        "  v1 = v1/la.norm(v1) # convert to unit vector\n",
        "  v2 = v2/la.norm(v2)\n",
        "  return np.dot(v1,v2) # compute dot product"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrTA6mLu1Ifa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "72bf29b4-6104-4897-d6ea-94fa8dd088f2"
      },
      "source": [
        "# Text Cleaning & Preprocessing\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Cleans text of punctuation and stopwords\n",
        "def pre_process(raw_text):\n",
        "    raw_text = raw_text.lower()\n",
        "    text_list = word_tokenize(raw_text)\n",
        "    text_list = [word.lower() for word in text_list if word.lower() not in stopwords.words('english') and word not in string.punctuation]\n",
        "    return text_list\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH5RJAgTdVfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building Dictionaries\n",
        "def addAllToDict(raw_doc, curr_dict):\n",
        "  text_list = pre_process(raw_doc)\n",
        "  for word in text_list:\n",
        "    # add to dictionary\n",
        "    val = curr_dict.setdefault(word,0)\n",
        "    curr_dict[word] = val+1\n",
        "  return len(text_list)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxSiWG5VhKPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs are Dictionaries\n",
        "def createOperandsFromDict(d1,n1,d2,n2):\n",
        "  d1 = d1.copy()\n",
        "  d2 = d2.copy() \n",
        "  for e in d1:\n",
        "    d2.setdefault(e,0) # if not in doc_cmp, add word set value to 0\n",
        "  for e in d2:\n",
        "    d1.setdefault(e,0) # if e not in vocab_cmp, add word and set val to 0\n",
        "  # create final comparison vectors\n",
        "  d1 = np.array([e[1] for e in sorted(d1.items())], dtype=np.double)/n1\n",
        "  d2 = np.array([e[1] for e in sorted(d2.items())], dtype=np.double)/n2\n",
        "  return (d1,d2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDQyvzsObC9u",
        "colab_type": "text"
      },
      "source": [
        "Begin Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeSMoGydzfNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59
        },
        "outputId": "f324b019-53a2-4a23-9c76-7ebabcfaf302"
      },
      "source": [
        "# Import Data Set\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True, return_X_y=False)\n",
        "newsgroups_test = fetch_20newsgroups(data_home=None, subset='test', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True, return_X_y=False)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkaiF3n6c5KI",
        "colab_type": "text"
      },
      "source": [
        "Train Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psrMqCHK4cNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Train Variables\n",
        "data = newsgroups_train.data\n",
        "indices = newsgroups_train.target\n",
        "categories = newsgroups_train.target_names"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXffpArElZuz",
        "colab_type": "text"
      },
      "source": [
        "Build the Collective Vocabulary for each category:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-zSIL-cg0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "cb8ae806-813a-4ce9-f5d9-406e0f48fc3e"
      },
      "source": [
        "# Building Dictionaries\n",
        "data_len = len(indices)\n",
        "total_words = [0]*20\n",
        "\n",
        "pC1 = progressCounter(data_len, 'Training')\n",
        "\n",
        "# instantiate empty dicts\n",
        "vocab_dict = [0]*20\n",
        "for i in range(20):\n",
        "  vocab_dict[i] = dict()\n",
        "\n",
        "# create the dictionaries\n",
        "for i in range(data_len):\n",
        "  index = indices[i] # select category \n",
        "  num_words = addAllToDict(data[i], vocab_dict[index])\n",
        "  total_words[index] += num_words\n",
        "\n",
        "  pC1.check_pt(i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress: 100%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Q5sux9c8g6",
        "colab_type": "text"
      },
      "source": [
        "Test Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjW99JdG38ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = newsgroups_test.data\n",
        "pred_true = newsgroups_test.target\n",
        "categories = newsgroups_test.target_names"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgFci8CdeCYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "c12eb16a-0ed9-4e71-de1d-1d839d51e0ca"
      },
      "source": [
        "# Building Doc Vector (Test Data)\n",
        "\n",
        "hits = 0\n",
        "misses = 0\n",
        "total_data_len = len(pred_true)\n",
        "pc2 = progressCounter(total_data_len, 'Testing')\n",
        "for i in range(total_data_len):  #outer layer cover all examples in data_len\n",
        "\n",
        "  # create doc dictionary\n",
        "  doc_dict = dict()\n",
        "  num_words = addAllToDict(data[i],doc_dict)\n",
        "\n",
        "  # Comparisons Begin\n",
        "  prob = [0]*20\n",
        "  for j in range(20): #loop through categories\n",
        "\n",
        "    (doc_cmp, vocab_cmp) = createOperandsFromDict(doc_dict,num_words,vocab_dict[j],total_words[j])\n",
        "\n",
        "    prob[j] = compute_cosine_similarity(doc_cmp, vocab_cmp)\n",
        "\n",
        "  #endfor\n",
        "  val = max(prob)\n",
        "  pred = prob.index(val)\n",
        "\n",
        "  if pred == pred_true[i]:\n",
        "    hits+=1\n",
        "  else:\n",
        "    misses+=1\n",
        "\n",
        "  pc2.check_pt(i)\n",
        "#endfor\n",
        "acc = int(hits/(hits+misses)*100)\n",
        "print(\"Accuracy = {0}%\".format(acc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Progress: 2%"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}